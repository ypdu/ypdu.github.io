<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Yupei Du</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Inline CSS -->
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
            color: #333;
        }

        header, main, footer {
            margin: 0 auto;
            max-width: 800px;
            padding: 20px;
        }

        header h1 {
            text-align: center;
            font-size: 2.5em;
        }

        .profile {
            display: flex;
            align-items: center;
            margin-bottom: 40px;
        }

        .profile img {
            border-radius: 50%;
            margin-right: 20px;
            width: 140px;
            height: 140px;
        }

        .contact-info p {
            margin: 5px 0;
        }

        .contact-info a {
            color: #007BFF;
            text-decoration: none;
        }

        .contact-info a:hover {
            text-decoration: underline;
        }

        h2 {
            border-bottom: 2px solid #eaeaea;
            padding-bottom: 10px;
            margin-top: 40px;
        }

        h3 {
            margin-top: 30px;
            color: #555;
        }

        ul {
            list-style-type: none;
            padding: 0;
        }

        li {
            margin-bottom: 20px;
        }

        li p {
            margin: 0;
        }

        .publications li {
            margin-bottom: 30px;
        }

        .publications p {
            margin: 5px 0;
        }

        footer {
            text-align: center;
            font-size: 0.9em;
            color: #777;
            border-top: 1px solid #eaeaea;
            padding-top: 10px;
            margin-top: 40px;
        }

        @media (max-width: 600px) {
            .profile {
                flex-direction: column;
                align-items: flex-start;
            }

            .profile img {
                margin-bottom: 20px;
                margin-right: 0;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>Yupei Du</h1>
    </header>
    <main>
        <!-- Profile Section -->
        <section class="profile">
            <img src="avatar.jpg" alt="Yupei Du">
            <div class="contact-info">
                <p>Ph.D. student at Utrecht University</p>
                <p>Email: y [dot] du [at] uu [dot] nl</p>
                <p>Address: BBG 5.05, 3584CC Utrecht, the Netherlands</p>
                <p>
                    <!-- Uncomment or add social links as needed -->
                    <!-- <a href="https://github.com/Yupei-Du">GitHub</a> | -->
                    <!-- <a href="https://twitter.com/YupeiDu">Twitter</a> | -->
                    <a href="https://scholar.google.com/citations?user=IgikFuEAAAAJ&hl=en-US">Google Scholar</a> |
                    <a href="resume.pdf">CV</a>
                    <!-- <a href="https://yupei.hashnode.dev/">Hashnode Blog</a> -->
                </p>
            </div>
        </section>

        <!-- Short Bio -->
        <section class="bio">
            <h2>Short Bio</h2>
            <p> I am a final-year Ph.D. student at Utrecht University, 
                advised by <a href="https://www.dongnguyen.nl/">Dr. Dong Nguyen</a> 
                and <a href="https://albertgatt.github.io/">Prof. Albert Gatt</a>.
                I work on NLP and ML, and I am now interested in the <strong>attribution</strong> of language models, 
                with a focus on reasoning tasks. 
                I believe this is a key to building safe and reliable AI systems.
            </p>
            <p>Before joining UU, I received both my bachelor’s (Psychology, 2017) and my master’s (Computer Science, 2020, 
                advised by <a href="https://ybwu.org/">Dr. Yuanbin Wu</a>) degrees from East China Normal University.</p>
            <p> 
                I am joining Saarland University as a postdoc with 
                <a href="https://www.coli.uni-saarland.de/~koller/">Prof. Alexander Koller</a> from Sep. 2025.
            </p>
        </section>

        <!-- Selected Publications -->
        <section class="publications">
            <h2>Selected Publications</h2>
            (* indicates equal contribution)
            <ul>
                <li>
                    <p><strong><em>Reason to Rote: Rethinking Memorization in Reasoning.</em></strong> 
                        arXiv preprint 2025.  
                        <a href="https://arxiv.org/pdf/2507.04782">[pdf]</a>
                    </p>  
                    <p><i>Yupei Du</i>, Philipp Mondorf, Silvia Casola, Yuekun Yao, Robert Litschko, and Barbara Plank.</p>
                        <i><strong>TL;DR:</strong> 
                            We mechanistically study benign memorization in language models in reasoning tasks, 
                            and find that memorization does not replace but rather <strong>is built on generalization</strong></i>.
                        </i>
                </li>
                <li>
                    <p><strong><em>Grokking ExPLAIND: Unifying Model, Data, and Training Attribution to Study Model Behavior.</em></strong> 
                        arXiv preprint 2025.  
                        <a href="https://arxiv.org/pdf/2505.20076">[pdf]</a>
                    </p>  
                    <p>Florian Eichin, <i>Yupei Du</i>, Philipp Mondorf, Barbara Plank, Michael A. Hedderich.</p>
                        <i><strong>TL;DR:</strong> We introduce ExPLAIND—an interpretability framework for jointly attributing model components, 
                            data, and training dynamics and apply it to investigate Grokking</i>.
                </li>
                <li>
                    <p><strong><em>Language models can learn implicit multi-hop reasoning, but only if they have lots of training data.</em></strong> 
                        arXiv preprint 2025.  
                        <a href="https://www.arxiv.org/pdf/2505.17923">[pdf]</a>
                    </p>  
                    <p>Yuekun Yao, <i>Yupei Du</i>, Dawei Zhu, Michael Hahn*, and Alexander Koller*.</p>
                        <i><strong>TL;DR:</strong> We studied the implicit multi-hop reasoning capabilities of language models, 
                        and find that they require an exponentially increasing amount of training data to perform well 
                        as the depth grows, and curriculum learning can substantially mitigate this</i>. 
                </li>
                <li>
                    <p><strong><em>Disentangling the Roles of Representation and Selection in Data Pruning.</em></strong> 
                        ACL 2025.  
                        <a href="https://arxiv.org/pdf/2507.03648">[pdf]</a>
                    </p>  
                    <p><i>Yupei Du</i>, Yingjin Song, Hugh Mee Wong, Daniil Ignatev, Albert Gatt, and Dong Nguyen.</p>
                        <i><strong>TL;DR:</strong> We disentangled and systematically studied 
                            the influence of data representation and selection algorithm in data pruning</i>.
                </li>
                <li>
                    <p><strong><em>On Support Samples of Next Word Prediction.</em></strong> 
                        ACL 2025.  
                        <a href="https://arxiv.org/pdf/2506.04047">[pdf]</a>
                    </p>  
                    <p>Yuqian Li*, <i>Yupei Du*</i>, Yufang Liu, Feifei Feng, Mou Xiao Feng, and Yuanbin Wu.</p>
                        <i><strong>TL;DR:</strong>We studied the training instances that support the predictions of language models,
                            and reveal that supporting is likely an <strong>intrinsic</strong> property of data</i>.
                </li>
                <li>
                    <p><strong><em>Burn After Reading: Do Multimodal Large Language Models Truly Capture Order of Events in Image Sequences?</em></strong> 
                        Findings of ACL 2025.  
                        <a href="https://arxiv.org/pdf/2506.10415">[pdf]</a>
                    </p>  
                    <p>Yingjin Song, <i>Yupei Du</i>, Denis Paperno, and Albert Gatt.</p>
                        <i><strong>TL;DR:</strong>We propose a vision-language benchmark for multi-event temporal grounding and reasoning in image sequences.</i>.
                </li>
                <li>
                    <p><strong><em>FTFT: Efficient and Robust Fine-Tuning by Transferring Training Dynamics.</em></strong> 
                        COLING 2025. 
                        <a href="https://arxiv.org/pdf/2310.06588.pdf">[pdf]</a></p>  
                    <p><i>Yupei Du</i>, Albert Gatt, and Dong Nguyen.</p>
                        <i><strong>TL;DR:</strong> We show that the training dynamics of an efficient but weak model  
                        can be <strong>transferred</strong> to much more capable models to achieve better robustness and efficiency</i>.
                </li>
                <!-- <li>
                    <p> Goya van Boven, <i>Yupei Du</i>, and Dong Nguyen.</p>
                    <p><strong><em>Transforming Dutch: Debiasing Dutch Coreference Resolution Systems for Non-binary Pronouns.</em></strong> 
                        FAccT 2024. 
                        <a href="https://arxiv.org/pdf/2405.00134">[pdf]</a></p>
                        <i><strong>TL;DR:</strong> We show that <strong>few-shot</strong> counterfactual data augmentation 
                        can effectively debias Dutch coreference resolution systems for non-binary pronouns.</i>
                </li> -->
                <!-- <li>
                    <p><i>Yupei Du</i> and Dong Nguyen.</p>
                    <p><strong><em>Measuring the Instability of Fine-Tuning.</em></strong> ACL 2023. <a href="https://arxiv.org/pdf/2302.07778">[pdf]</a></p>
                </li> -->
                <li>
                    <p><strong><em>Understanding Gender Bias in Knowledge Base Embeddings.</em></strong> ACL 2022. <a href="https://aclanthology.org/2022.acl-long.98.pdf">[pdf]</a></p>
                    <p><i>Yupei Du</i>, Qi Zheng, Yuanbin Wu, Man Lan, Yan Yang, Meirong Ma.</p>
                    <i><strong>TL;DR:</strong> 
                        We propose methods to <strong>both quantify and trace the origins of gender biases</strong> in knowledge base (embeddings), 
                        using a closed-form approximation of influence functions.</i>
                </li>
                <!-- <li>
                    <p><i>Yupei Du</i>, Qixiang Fang, Dong Nguyen.</p>
                    <p><strong><em>Assessing the Reliability of Word Embedding Gender Bias Measures.</em></strong> EMNLP 2021. <a href="https://arxiv.org/pdf/2109.04732.pdf">[pdf]</a></p>
                </li> -->
                <!-- Uncomment the following publication if you wish to include it -->
                <!--
                <li>
                    <p>Guanyi Chen, Yinhe Zheng, <i>Yupei Du</i>.</p>
                    <p><strong><em>Listener's Social Identity Matters in Personalised Response Generation.</em></strong> INLG 2020. <a href="https://www.aclweb.org/anthology/2020.inlg-1.26.pdf">[pdf]</a></p>
                </li>
                -->
                <li>
                    <p><strong><em>Exploring Human Gender Stereotypes with Word Association Test.</em></strong> EMNLP 2019. <a href="https://www.aclweb.org/anthology/D19-1635.pdf">[pdf]</a></p>
                    <p><i>Yupei Du</i>, Yuanbin Wu, Man Lan.</p>
                    <i><strong>TL;DR:</strong> 
                        We use label propagation to <strong>quantify and visualize</strong> 
                        how gender biases are transferred and reinforced through word associations, 
                        and therefore offer a large-scale dataset of word-level gender bias scores.</i>
                    </i>
                </li>
            </ul>
        </section>



        <!-- Work Experience -->
        <section class="work-experience">
            <h2>Experience</h2>
            <ul>
                <li>
                    <p>Visiting PhD researcher at LMU Munich, Munich, Germany. Jan. 2025 – Mar. 2025.</p>
                    <p>Advised by <a href="https://bplank.github.io/">Prof. Barbara Plank</a> at <a href="https://mainlp.github.io/">MaiNLP</a>.</p>
                </li>
                <li>
                    <p>Applied Scientist Intern at Amazon.com Inc., Berlin, Germany. Nov. 2022 – May 2023.</p>
                    <p>Mentored by <a href="https://www.bifold.berlin/people/prof-dr-ziawasch-abedjan.html">Prof. Ziawasch Abedjan</a>.</p>
                </li>
                <li>
                    <p>Research Intern at Sogou Inc., Hangzhou, China. Jul. 2019 – Jan. 2020.</p>
                </li>
            </ul>
        </section>

        <!-- Services -->
        <section class="services">
            <h2>Services</h2>
            <ul>
                <li>
                    <p>Program Committee (2021–): ACL, EMNLP, NAACL, EACL. (2024-): COLM</p>
                </li>
                <li>
                    <p>Outstanding Reviewer: ACL 2022.</p>
                </li>
            </ul>
        </section>

    </main>

    <!-- Footer -->
    <footer>
        <p>Style generated with o1-preview :)</p>
    </footer>
</body>
</html>

